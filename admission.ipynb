{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9cb5d1fc",
      "metadata": {
        "id": "9cb5d1fc"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "url = \"https://raw.githubusercontent.com/PRABHAV-RA2011003011010/Graduate_Admission_Prediction/refs/heads/main/Admission_Predict.csv\"\n",
        "df = pd.read_csv(url)\n",
        "print(df.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jPjOCxV8PrCx",
        "outputId": "e65b08af-4548-4482-9657-fe3c3750d75d"
      },
      "id": "jPjOCxV8PrCx",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   Serial No.  GRE Score  TOEFL Score  University Rating  SOP  LOR   CGPA  \\\n",
            "0           1        337          118                  4  4.5   4.5  9.65   \n",
            "1           2        324          107                  4  4.0   4.5  8.87   \n",
            "2           3        316          104                  3  3.0   3.5  8.00   \n",
            "3           4        322          110                  3  3.5   2.5  8.67   \n",
            "4           5        314          103                  2  2.0   3.0  8.21   \n",
            "\n",
            "   Research  Chance of Admit   \n",
            "0         1              0.92  \n",
            "1         1              0.76  \n",
            "2         1              0.72  \n",
            "3         1              0.80  \n",
            "4         0              0.65  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UhdWmvaLPrG_",
        "outputId": "e33728a8-2376-489f-81d5-74c8723c82d6"
      },
      "id": "UhdWmvaLPrG_",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(400, 9)"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kqKuarwEQzCT",
        "outputId": "51334541-4bca-411f-9259-60f52cbc92ac"
      },
      "id": "kqKuarwEQzCT",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 400 entries, 0 to 399\n",
            "Data columns (total 9 columns):\n",
            " #   Column             Non-Null Count  Dtype  \n",
            "---  ------             --------------  -----  \n",
            " 0   Serial No.         400 non-null    int64  \n",
            " 1   GRE Score          400 non-null    int64  \n",
            " 2   TOEFL Score        400 non-null    int64  \n",
            " 3   University Rating  400 non-null    int64  \n",
            " 4   SOP                400 non-null    float64\n",
            " 5   LOR                400 non-null    float64\n",
            " 6   CGPA               400 non-null    float64\n",
            " 7   Research           400 non-null    int64  \n",
            " 8   Chance of Admit    400 non-null    float64\n",
            "dtypes: float64(4), int64(5)\n",
            "memory usage: 28.3 KB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.duplicated().sum()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8X4rwq-wQzF9",
        "outputId": "45a717f3-6443-4888-8c51-47d08c369828"
      },
      "id": "8X4rwq-wQzF9",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "np.int64(0)"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.drop(columns=['Serial No.'],inplace=True)"
      ],
      "metadata": {
        "id": "45qn9U7lQzIe"
      },
      "id": "45qn9U7lQzIe",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "1Ky5HAPGQzLN",
        "outputId": "d4392e4f-b9d6-4670-91b0-e0c975f98928"
      },
      "id": "1Ky5HAPGQzLN",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   GRE Score  TOEFL Score  University Rating  SOP  LOR   CGPA  Research  \\\n",
              "0        337          118                  4  4.5   4.5  9.65         1   \n",
              "1        324          107                  4  4.0   4.5  8.87         1   \n",
              "2        316          104                  3  3.0   3.5  8.00         1   \n",
              "3        322          110                  3  3.5   2.5  8.67         1   \n",
              "4        314          103                  2  2.0   3.0  8.21         0   \n",
              "\n",
              "   Chance of Admit   \n",
              "0              0.92  \n",
              "1              0.76  \n",
              "2              0.72  \n",
              "3              0.80  \n",
              "4              0.65  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-801e41af-05c6-4c50-a691-8cde98423f4e\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>GRE Score</th>\n",
              "      <th>TOEFL Score</th>\n",
              "      <th>University Rating</th>\n",
              "      <th>SOP</th>\n",
              "      <th>LOR</th>\n",
              "      <th>CGPA</th>\n",
              "      <th>Research</th>\n",
              "      <th>Chance of Admit</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>337</td>\n",
              "      <td>118</td>\n",
              "      <td>4</td>\n",
              "      <td>4.5</td>\n",
              "      <td>4.5</td>\n",
              "      <td>9.65</td>\n",
              "      <td>1</td>\n",
              "      <td>0.92</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>324</td>\n",
              "      <td>107</td>\n",
              "      <td>4</td>\n",
              "      <td>4.0</td>\n",
              "      <td>4.5</td>\n",
              "      <td>8.87</td>\n",
              "      <td>1</td>\n",
              "      <td>0.76</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>316</td>\n",
              "      <td>104</td>\n",
              "      <td>3</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3.5</td>\n",
              "      <td>8.00</td>\n",
              "      <td>1</td>\n",
              "      <td>0.72</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>322</td>\n",
              "      <td>110</td>\n",
              "      <td>3</td>\n",
              "      <td>3.5</td>\n",
              "      <td>2.5</td>\n",
              "      <td>8.67</td>\n",
              "      <td>1</td>\n",
              "      <td>0.80</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>314</td>\n",
              "      <td>103</td>\n",
              "      <td>2</td>\n",
              "      <td>2.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>8.21</td>\n",
              "      <td>0</td>\n",
              "      <td>0.65</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-801e41af-05c6-4c50-a691-8cde98423f4e')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-801e41af-05c6-4c50-a691-8cde98423f4e button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-801e41af-05c6-4c50-a691-8cde98423f4e');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-b0d65705-9152-4a5d-9482-b997ea4f42a0\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-b0d65705-9152-4a5d-9482-b997ea4f42a0')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-b0d65705-9152-4a5d-9482-b997ea4f42a0 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 400,\n  \"fields\": [\n    {\n      \"column\": \"GRE Score\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 11,\n        \"min\": 290,\n        \"max\": 340,\n        \"num_unique_values\": 49,\n        \"samples\": [\n          307,\n          335,\n          297\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"TOEFL Score\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 6,\n        \"min\": 92,\n        \"max\": 120,\n        \"num_unique_values\": 29,\n        \"samples\": [\n          94,\n          119,\n          112\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"University Rating\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1,\n        \"min\": 1,\n        \"max\": 5,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          3,\n          1,\n          2\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"SOP\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1.0068686414586976,\n        \"min\": 1.0,\n        \"max\": 5.0,\n        \"num_unique_values\": 9,\n        \"samples\": [\n          1.0,\n          4.0,\n          5.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"LOR \",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.898477548279256,\n        \"min\": 1.0,\n        \"max\": 5.0,\n        \"num_unique_values\": 9,\n        \"samples\": [\n          5.0,\n          3.5,\n          1.5\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"CGPA\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.5963170964964317,\n        \"min\": 6.8,\n        \"max\": 9.92,\n        \"num_unique_values\": 168,\n        \"samples\": [\n          8.15,\n          7.4,\n          9.91\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Research\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0,\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Chance of Admit \",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.14260933017384092,\n        \"min\": 0.34,\n        \"max\": 0.97,\n        \"num_unique_values\": 60,\n        \"samples\": [\n          0.92,\n          0.9\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X=df.iloc[:,0:-1]\n",
        "Y=df.iloc[:,-1]"
      ],
      "metadata": {
        "id": "R8FsW3Z6QzNy"
      },
      "id": "R8FsW3Z6QzNy",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "rEuAJGYaQzQ7",
        "outputId": "45d418d6-e065-4aad-8454-ce2f952018cb"
      },
      "id": "rEuAJGYaQzQ7",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     GRE Score  TOEFL Score  University Rating  SOP  LOR   CGPA  Research\n",
              "0          337          118                  4  4.5   4.5  9.65         1\n",
              "1          324          107                  4  4.0   4.5  8.87         1\n",
              "2          316          104                  3  3.0   3.5  8.00         1\n",
              "3          322          110                  3  3.5   2.5  8.67         1\n",
              "4          314          103                  2  2.0   3.0  8.21         0\n",
              "..         ...          ...                ...  ...   ...   ...       ...\n",
              "395        324          110                  3  3.5   3.5  9.04         1\n",
              "396        325          107                  3  3.0   3.5  9.11         1\n",
              "397        330          116                  4  5.0   4.5  9.45         1\n",
              "398        312          103                  3  3.5   4.0  8.78         0\n",
              "399        333          117                  4  5.0   4.0  9.66         1\n",
              "\n",
              "[400 rows x 7 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-cb53a6bd-932d-400d-981a-bc72656f395d\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>GRE Score</th>\n",
              "      <th>TOEFL Score</th>\n",
              "      <th>University Rating</th>\n",
              "      <th>SOP</th>\n",
              "      <th>LOR</th>\n",
              "      <th>CGPA</th>\n",
              "      <th>Research</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>337</td>\n",
              "      <td>118</td>\n",
              "      <td>4</td>\n",
              "      <td>4.5</td>\n",
              "      <td>4.5</td>\n",
              "      <td>9.65</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>324</td>\n",
              "      <td>107</td>\n",
              "      <td>4</td>\n",
              "      <td>4.0</td>\n",
              "      <td>4.5</td>\n",
              "      <td>8.87</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>316</td>\n",
              "      <td>104</td>\n",
              "      <td>3</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3.5</td>\n",
              "      <td>8.00</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>322</td>\n",
              "      <td>110</td>\n",
              "      <td>3</td>\n",
              "      <td>3.5</td>\n",
              "      <td>2.5</td>\n",
              "      <td>8.67</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>314</td>\n",
              "      <td>103</td>\n",
              "      <td>2</td>\n",
              "      <td>2.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>8.21</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>395</th>\n",
              "      <td>324</td>\n",
              "      <td>110</td>\n",
              "      <td>3</td>\n",
              "      <td>3.5</td>\n",
              "      <td>3.5</td>\n",
              "      <td>9.04</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>396</th>\n",
              "      <td>325</td>\n",
              "      <td>107</td>\n",
              "      <td>3</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3.5</td>\n",
              "      <td>9.11</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>397</th>\n",
              "      <td>330</td>\n",
              "      <td>116</td>\n",
              "      <td>4</td>\n",
              "      <td>5.0</td>\n",
              "      <td>4.5</td>\n",
              "      <td>9.45</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>398</th>\n",
              "      <td>312</td>\n",
              "      <td>103</td>\n",
              "      <td>3</td>\n",
              "      <td>3.5</td>\n",
              "      <td>4.0</td>\n",
              "      <td>8.78</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>399</th>\n",
              "      <td>333</td>\n",
              "      <td>117</td>\n",
              "      <td>4</td>\n",
              "      <td>5.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>9.66</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>400 rows × 7 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-cb53a6bd-932d-400d-981a-bc72656f395d')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-cb53a6bd-932d-400d-981a-bc72656f395d button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-cb53a6bd-932d-400d-981a-bc72656f395d');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-4aa3a7f9-707c-433d-a909-1572287db3d2\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-4aa3a7f9-707c-433d-a909-1572287db3d2')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-4aa3a7f9-707c-433d-a909-1572287db3d2 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "  <div id=\"id_c1699e89-f1d0-4fd6-817f-6c09ca3358b4\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('X')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_c1699e89-f1d0-4fd6-817f-6c09ca3358b4 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('X');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "X",
              "summary": "{\n  \"name\": \"X\",\n  \"rows\": 400,\n  \"fields\": [\n    {\n      \"column\": \"GRE Score\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 11,\n        \"min\": 290,\n        \"max\": 340,\n        \"num_unique_values\": 49,\n        \"samples\": [\n          307,\n          335,\n          297\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"TOEFL Score\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 6,\n        \"min\": 92,\n        \"max\": 120,\n        \"num_unique_values\": 29,\n        \"samples\": [\n          94,\n          119,\n          112\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"University Rating\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1,\n        \"min\": 1,\n        \"max\": 5,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          3,\n          1,\n          2\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"SOP\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1.0068686414586976,\n        \"min\": 1.0,\n        \"max\": 5.0,\n        \"num_unique_values\": 9,\n        \"samples\": [\n          1.0,\n          4.0,\n          5.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"LOR \",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.898477548279256,\n        \"min\": 1.0,\n        \"max\": 5.0,\n        \"num_unique_values\": 9,\n        \"samples\": [\n          5.0,\n          3.5,\n          1.5\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"CGPA\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.5963170964964317,\n        \"min\": 6.8,\n        \"max\": 9.92,\n        \"num_unique_values\": 168,\n        \"samples\": [\n          8.15,\n          7.4,\n          9.91\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Research\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0,\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Y"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 458
        },
        "id": "LuntSLeZREzr",
        "outputId": "b4ddef85-8c98-4e6d-b2ab-460866c3bf3e"
      },
      "id": "LuntSLeZREzr",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0      0.92\n",
              "1      0.76\n",
              "2      0.72\n",
              "3      0.80\n",
              "4      0.65\n",
              "       ... \n",
              "395    0.82\n",
              "396    0.84\n",
              "397    0.91\n",
              "398    0.67\n",
              "399    0.95\n",
              "Name: Chance of Admit , Length: 400, dtype: float64"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Chance of Admit</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.92</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.76</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.72</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.80</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.65</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>395</th>\n",
              "      <td>0.82</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>396</th>\n",
              "      <td>0.84</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>397</th>\n",
              "      <td>0.91</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>398</th>\n",
              "      <td>0.67</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>399</th>\n",
              "      <td>0.95</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>400 rows × 1 columns</p>\n",
              "</div><br><label><b>dtype:</b> float64</label>"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train,X_test,y_train,y_test=train_test_split(X,Y,test_size=0.2,random_state=1)"
      ],
      "metadata": {
        "id": "a6x4_X36RE3L"
      },
      "id": "a6x4_X36RE3L",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PgGduT4QRE7c",
        "outputId": "45e4653b-8028-46ea-806c-e5d0578ffba7"
      },
      "id": "PgGduT4QRE7c",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(320, 7)"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import MinMaxScaler\n",
        "scaler=MinMaxScaler()\n",
        "\n",
        "X_train_scaled= scaler.fit_transform(X_train)\n",
        "X_test_scaled=scaler.transform(X_test)"
      ],
      "metadata": {
        "id": "0qZeWmtaRE-6"
      },
      "id": "0qZeWmtaRE-6",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_scaled[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bnOJThf9RFCB",
        "outputId": "94ed9323-91ff-421e-ccde-da98860b1723"
      },
      "id": "bnOJThf9RFCB",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.22      , 0.17857143, 0.25      , 0.5       , 0.42857143,\n",
              "       0.25      , 1.        ])"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Covert Numpy arrays to Pytorch tensors"
      ],
      "metadata": {
        "id": "SBzxXhH0YDuy"
      },
      "id": "SBzxXhH0YDuy"
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_tensor = torch.from_numpy(X_train.values.astype(np.float32))\n",
        "X_test_tensor = torch.from_numpy(X_test.values.astype(np.float32))\n",
        "y_train_tensor = torch.from_numpy(y_train.values.astype(np.float32))\n",
        "y_test_tensor = torch.from_numpy(y_test.values.astype(np.float32))"
      ],
      "metadata": {
        "id": "_Me8OkOrYDbS"
      },
      "id": "_Me8OkOrYDbS",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_train_tensor"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2x5uqjQcYDVU",
        "outputId": "62be0167-f4e9-4809-a181-87ba3341ef64"
      },
      "id": "2x5uqjQcYDVU",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0.4400, 0.9500, 0.7100, 0.6200, 0.6400, 0.4700, 0.7300, 0.9600, 0.7100,\n",
              "        0.7800, 0.5200, 0.7300, 0.8000, 0.8100, 0.5300, 0.6200, 0.7000, 0.7900,\n",
              "        0.8700, 0.8900, 0.9200, 0.5700, 0.7300, 0.4400, 0.7400, 0.8400, 0.8400,\n",
              "        0.6400, 0.9000, 0.7400, 0.7100, 0.4700, 0.9000, 0.6300, 0.7500, 0.3800,\n",
              "        0.7200, 0.8000, 0.8400, 0.8200, 0.4800, 0.6400, 0.6200, 0.7500, 0.7300,\n",
              "        0.4200, 0.9400, 0.7800, 0.7000, 0.9500, 0.7100, 0.6400, 0.7200, 0.8900,\n",
              "        0.7000, 0.6800, 0.6400, 0.7700, 0.5700, 0.3400, 0.6100, 0.6700, 0.6100,\n",
              "        0.8000, 0.6900, 0.5600, 0.6200, 0.4500, 0.8900, 0.6600, 0.7700, 0.9200,\n",
              "        0.6900, 0.8800, 0.8200, 0.7500, 0.9400, 0.5200, 0.9300, 0.6400, 0.6800,\n",
              "        0.7100, 0.5600, 0.8100, 0.7000, 0.5300, 0.5700, 0.7300, 0.8700, 0.7000,\n",
              "        0.4700, 0.8400, 0.8000, 0.9300, 0.8600, 0.8300, 0.6200, 0.7100, 0.9400,\n",
              "        0.6100, 0.8500, 0.8100, 0.8200, 0.3900, 0.8000, 0.6200, 0.9200, 0.6100,\n",
              "        0.5200, 0.9100, 0.5400, 0.8500, 0.7700, 0.9300, 0.4900, 0.6500, 0.4600,\n",
              "        0.7100, 0.9400, 0.5000, 0.8600, 0.7900, 0.5700, 0.4300, 0.7500, 0.4600,\n",
              "        0.7400, 0.6400, 0.7100, 0.9100, 0.5800, 0.8200, 0.7300, 0.7800, 0.7900,\n",
              "        0.9000, 0.7300, 0.8800, 0.7300, 0.5600, 0.6500, 0.8400, 0.8600, 0.6900,\n",
              "        0.6100, 0.7600, 0.6200, 0.7100, 0.7800, 0.6400, 0.6200, 0.8800, 0.6300,\n",
              "        0.6400, 0.7500, 0.8900, 0.7200, 0.8200, 0.7400, 0.7400, 0.4600, 0.7000,\n",
              "        0.6400, 0.8100, 0.7800, 0.7200, 0.7200, 0.9600, 0.7100, 0.9700, 0.8100,\n",
              "        0.9300, 0.7200, 0.5700, 0.8900, 0.7900, 0.5600, 0.9500, 0.9100, 0.5900,\n",
              "        0.9400, 0.7400, 0.8500, 0.6400, 0.6500, 0.6100, 0.5600, 0.7100, 0.8600,\n",
              "        0.5900, 0.4700, 0.6600, 0.6800, 0.4700, 0.7000, 0.9000, 0.7700, 0.7000,\n",
              "        0.6800, 0.6900, 0.5700, 0.7600, 0.9600, 0.5800, 0.4800, 0.3600, 0.9400,\n",
              "        0.8400, 0.9600, 0.9700, 0.8600, 0.6300, 0.5200, 0.7700, 0.4800, 0.7900,\n",
              "        0.6000, 0.4600, 0.7900, 0.6400, 0.8100, 0.6400, 0.6300, 0.7200, 0.7300,\n",
              "        0.6400, 0.7000, 0.8900, 0.7900, 0.3800, 0.7200, 0.7800, 0.7000, 0.9300,\n",
              "        0.9000, 0.7500, 0.9400, 0.6900, 0.6500, 0.9000, 0.7400, 0.7600, 0.4600,\n",
              "        0.6600, 0.5900, 0.9700, 0.7300, 0.7200, 0.8200, 0.7600, 0.6500, 0.9200,\n",
              "        0.7900, 0.7700, 0.6700, 0.8500, 0.7800, 0.7100, 0.6700, 0.7400, 0.7900,\n",
              "        0.8100, 0.6300, 0.9400, 0.7300, 0.5200, 0.5400, 0.8600, 0.6800, 0.7200,\n",
              "        0.6900, 0.7600, 0.7400, 0.8700, 0.6800, 0.8000, 0.5100, 0.7800, 0.4900,\n",
              "        0.6500, 0.9400, 0.6600, 0.7900, 0.9100, 0.7500, 0.6800, 0.5400, 0.7600,\n",
              "        0.6700, 0.9400, 0.5800, 0.8000, 0.6800, 0.9000, 0.7200, 0.6400, 0.6500,\n",
              "        0.9300, 0.6800, 0.7600, 0.7000, 0.7100, 0.6800, 0.8500, 0.8900, 0.7200,\n",
              "        0.8000, 0.8600, 0.9600, 0.9200, 0.8000, 0.8300, 0.7900, 0.9700, 0.7700,\n",
              "        0.7900, 0.9300, 0.8400, 0.8800, 0.5800])"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_train_tensor.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UaXItdIjZsR_",
        "outputId": "5d44500a-de87-45a5-fbc5-d78685c4bbe5"
      },
      "id": "UaXItdIjZsR_",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([320])"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Pytorch Starts!!!"
      ],
      "metadata": {
        "id": "55i6zcrJRz3l"
      },
      "id": "55i6zcrJRz3l"
    },
    {
      "cell_type": "code",
      "source": [
        "#Dataset and DataLoader\n",
        "from torch.utils.data import Dataset,DataLoader"
      ],
      "metadata": {
        "id": "zL4VYhFd5rBT"
      },
      "id": "zL4VYhFd5rBT",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class CustomDataset(Dataset):\n",
        "\n",
        "  def __init__(self,x_tensor,y_tensor):\n",
        "    self.x=x_tensor\n",
        "    self.y=y_tensor\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.x)\n",
        "\n",
        "  def __getitem__(self,index):\n",
        "    return (self.x[index],self.y[index])"
      ],
      "metadata": {
        "id": "WWiKu9wj6WTe"
      },
      "id": "WWiKu9wj6WTe",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = CustomDataset(X_train_tensor,y_train_tensor)\n",
        "test_dataset = CustomDataset(X_test_tensor,y_test_tensor)"
      ],
      "metadata": {
        "id": "3y4aam1u7DSH"
      },
      "id": "3y4aam1u7DSH",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(test_dataset)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NAH2ow8J7K-I",
        "outputId": "b03fa2ed-91d2-4b52-f921-c2494178ffbe"
      },
      "id": "NAH2ow8J7K-I",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "80"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5I8acBMO7bsQ",
        "outputId": "2ecc8731-6ea2-46ec-c7bd-adefb23cf44f"
      },
      "id": "5I8acBMO7bsQ",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([301.0000,  97.0000,   2.0000,   3.0000,   3.0000,   7.8800,   1.0000]),\n",
              " tensor(0.4400))"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataloader = DataLoader(train_dataset,batch_size=16,shuffle=True)\n",
        "test_dataloader = DataLoader(test_dataset,batch_size=16,shuffle=True)"
      ],
      "metadata": {
        "id": "4QvpBrAD7s_n"
      },
      "id": "4QvpBrAD7s_n",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(train_dataloader)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PRCBFYoR-OCM",
        "outputId": "02aed46c-1c39-4f5e-81bf-8b6dbadd5be1"
      },
      "id": "PRCBFYoR-OCM",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<torch.utils.data.dataloader.DataLoader object at 0x7ff289768c20>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for X,Y in train_dataloader:\n",
        "  print(X)\n",
        "  print(Y)\n",
        "  print(\".\"*50)"
      ],
      "metadata": {
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TcRy80AQ70e2",
        "outputId": "c8b0a979-d88b-40b0-97e0-e82f68e5c663"
      },
      "id": "TcRy80AQ70e2",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[331.0000, 116.0000,   5.0000,   4.0000,   4.0000,   9.2600,   1.0000],\n",
            "        [295.0000, 101.0000,   2.0000,   2.5000,   2.0000,   7.8600,   0.0000],\n",
            "        [329.0000, 113.0000,   5.0000,   5.0000,   4.5000,   9.4500,   1.0000],\n",
            "        [327.0000, 111.0000,   4.0000,   3.0000,   4.0000,   8.4000,   1.0000],\n",
            "        [320.0000, 120.0000,   3.0000,   4.0000,   4.5000,   9.1100,   0.0000],\n",
            "        [314.0000, 109.0000,   4.0000,   3.5000,   4.0000,   8.7700,   1.0000],\n",
            "        [339.0000, 114.0000,   5.0000,   4.0000,   4.5000,   9.7600,   1.0000],\n",
            "        [325.0000, 112.0000,   2.0000,   3.0000,   3.5000,   8.9600,   1.0000],\n",
            "        [318.0000, 106.0000,   3.0000,   2.0000,   3.0000,   8.6500,   0.0000],\n",
            "        [319.0000, 108.0000,   2.0000,   2.5000,   3.0000,   8.7600,   0.0000],\n",
            "        [323.0000, 107.0000,   3.0000,   3.5000,   3.5000,   8.5500,   1.0000],\n",
            "        [324.0000, 111.0000,   5.0000,   4.5000,   4.0000,   9.1600,   1.0000],\n",
            "        [311.0000, 105.0000,   2.0000,   3.0000,   2.0000,   8.1200,   1.0000],\n",
            "        [328.0000, 112.0000,   4.0000,   4.0000,   4.5000,   9.1000,   1.0000],\n",
            "        [329.0000, 111.0000,   4.0000,   4.5000,   4.0000,   9.0100,   1.0000],\n",
            "        [312.0000, 103.0000,   3.0000,   5.0000,   4.0000,   8.4500,   0.0000]])\n",
            "tensor([0.9300, 0.6900, 0.8900, 0.7800, 0.8600, 0.8200, 0.9600, 0.8000, 0.7100,\n",
            "        0.6600, 0.7300, 0.9000, 0.7300, 0.7800, 0.8100, 0.7600])\n",
            "..................................................\n",
            "tensor([[331.0000, 112.0000,   5.0000,   4.0000,   5.0000,   9.8000,   1.0000],\n",
            "        [316.0000, 109.0000,   4.0000,   4.5000,   3.5000,   8.7600,   1.0000],\n",
            "        [340.0000, 120.0000,   5.0000,   4.5000,   4.5000,   9.6000,   1.0000],\n",
            "        [311.0000, 104.0000,   3.0000,   3.5000,   2.0000,   8.2000,   1.0000],\n",
            "        [301.0000,  99.0000,   2.0000,   3.0000,   2.0000,   8.2200,   0.0000],\n",
            "        [302.0000,  99.0000,   2.0000,   1.0000,   2.0000,   7.9700,   0.0000],\n",
            "        [313.0000, 102.0000,   3.0000,   2.0000,   3.0000,   8.2700,   0.0000],\n",
            "        [325.0000, 114.0000,   3.0000,   3.5000,   3.0000,   9.0400,   1.0000],\n",
            "        [336.0000, 119.0000,   5.0000,   4.0000,   3.5000,   9.8000,   1.0000],\n",
            "        [298.0000,  99.0000,   1.0000,   1.5000,   3.0000,   7.4600,   0.0000],\n",
            "        [314.0000, 106.0000,   3.0000,   3.0000,   5.0000,   8.9000,   0.0000],\n",
            "        [336.0000, 112.0000,   5.0000,   5.0000,   5.0000,   9.7600,   1.0000],\n",
            "        [312.0000, 107.0000,   4.0000,   4.5000,   4.0000,   8.6500,   1.0000],\n",
            "        [316.0000, 100.0000,   2.0000,   1.5000,   3.0000,   8.1600,   1.0000],\n",
            "        [314.0000, 107.0000,   2.0000,   2.5000,   4.0000,   8.5600,   0.0000],\n",
            "        [309.0000,  99.0000,   3.0000,   4.0000,   4.0000,   8.5600,   0.0000]])\n",
            "tensor([0.9400, 0.7400, 0.9400, 0.6100, 0.6400, 0.5600, 0.6400, 0.7600, 0.9700,\n",
            "        0.5300, 0.7400, 0.9600, 0.7300, 0.7100, 0.6300, 0.7600])\n",
            "..................................................\n",
            "tensor([[317.0000, 107.0000,   3.0000,   4.0000,   3.0000,   8.7000,   0.0000],\n",
            "        [315.0000,  99.0000,   2.0000,   3.5000,   3.0000,   7.8900,   0.0000],\n",
            "        [340.0000, 120.0000,   5.0000,   4.5000,   4.5000,   9.9100,   1.0000],\n",
            "        [295.0000,  96.0000,   2.0000,   1.5000,   2.0000,   7.3400,   0.0000],\n",
            "        [324.0000, 112.0000,   4.0000,   4.0000,   2.5000,   8.1000,   1.0000],\n",
            "        [311.0000, 106.0000,   2.0000,   3.5000,   3.0000,   8.2600,   1.0000],\n",
            "        [317.0000, 107.0000,   2.0000,   3.5000,   3.0000,   8.2800,   0.0000],\n",
            "        [312.0000, 104.0000,   3.0000,   3.5000,   4.0000,   8.0900,   0.0000],\n",
            "        [326.0000, 111.0000,   5.0000,   4.5000,   4.0000,   9.2300,   1.0000],\n",
            "        [312.0000, 109.0000,   3.0000,   3.0000,   3.0000,   8.6900,   0.0000],\n",
            "        [299.0000, 100.0000,   1.0000,   1.5000,   2.0000,   7.8900,   0.0000],\n",
            "        [327.0000, 109.0000,   3.0000,   3.5000,   4.0000,   8.7700,   1.0000],\n",
            "        [300.0000,  99.0000,   1.0000,   1.0000,   2.5000,   8.0100,   0.0000],\n",
            "        [340.0000, 113.0000,   4.0000,   5.0000,   5.0000,   9.7400,   1.0000],\n",
            "        [297.0000, 100.0000,   1.0000,   1.5000,   2.0000,   7.9000,   0.0000],\n",
            "        [322.0000, 104.0000,   3.0000,   3.5000,   4.0000,   8.8400,   1.0000]])\n",
            "tensor([0.6600, 0.6300, 0.9700, 0.4700, 0.7200, 0.7900, 0.6600, 0.7100, 0.8800,\n",
            "        0.7700, 0.5900, 0.7900, 0.5800, 0.9600, 0.5200, 0.7800])\n",
            "..................................................\n",
            "tensor([[301.0000, 107.0000,   3.0000,   3.5000,   3.5000,   8.3400,   1.0000],\n",
            "        [315.0000, 106.0000,   3.0000,   4.5000,   3.5000,   8.4200,   0.0000],\n",
            "        [316.0000, 109.0000,   3.0000,   3.5000,   3.0000,   8.7600,   0.0000],\n",
            "        [310.0000, 104.0000,   3.0000,   2.0000,   3.5000,   8.3700,   0.0000],\n",
            "        [329.0000, 110.0000,   2.0000,   4.0000,   3.0000,   9.1500,   1.0000],\n",
            "        [295.0000,  99.0000,   2.0000,   2.5000,   3.0000,   7.6500,   0.0000],\n",
            "        [315.0000, 105.0000,   3.0000,   2.0000,   2.5000,   8.3400,   0.0000],\n",
            "        [308.0000, 106.0000,   3.0000,   3.5000,   2.5000,   8.2100,   1.0000],\n",
            "        [307.0000, 105.0000,   2.0000,   2.5000,   3.0000,   7.6500,   0.0000],\n",
            "        [321.0000, 114.0000,   4.0000,   4.0000,   5.0000,   9.1200,   0.0000],\n",
            "        [299.0000,  97.0000,   3.0000,   5.0000,   3.5000,   7.6600,   0.0000],\n",
            "        [312.0000,  98.0000,   1.0000,   3.5000,   3.0000,   8.1800,   1.0000],\n",
            "        [300.0000,  97.0000,   2.0000,   3.0000,   3.0000,   8.1000,   1.0000],\n",
            "        [326.0000, 112.0000,   4.0000,   4.0000,   3.5000,   9.1200,   1.0000],\n",
            "        [300.0000, 102.0000,   3.0000,   3.5000,   2.5000,   8.1700,   0.0000],\n",
            "        [325.0000, 112.0000,   4.0000,   4.0000,   4.5000,   9.1700,   1.0000]])\n",
            "tensor([0.6200, 0.7200, 0.7700, 0.7000, 0.8400, 0.5700, 0.7000, 0.7500, 0.5800,\n",
            "        0.8500, 0.3800, 0.6400, 0.6500, 0.8400, 0.6300, 0.8500])\n",
            "..................................................\n",
            "tensor([[308.0000, 104.0000,   2.0000,   2.5000,   3.0000,   8.0700,   0.0000],\n",
            "        [317.0000, 104.0000,   2.0000,   4.5000,   4.0000,   8.4700,   0.0000],\n",
            "        [318.0000, 112.0000,   3.0000,   4.0000,   3.5000,   8.6700,   0.0000],\n",
            "        [304.0000, 100.0000,   2.0000,   2.5000,   3.5000,   8.0700,   0.0000],\n",
            "        [327.0000, 112.0000,   3.0000,   3.0000,   3.0000,   8.7200,   1.0000],\n",
            "        [324.0000, 107.0000,   4.0000,   4.0000,   4.5000,   8.8700,   1.0000],\n",
            "        [331.0000, 120.0000,   3.0000,   4.0000,   4.0000,   8.9600,   1.0000],\n",
            "        [304.0000,  97.0000,   2.0000,   1.5000,   2.0000,   7.6400,   0.0000],\n",
            "        [314.0000, 107.0000,   3.0000,   3.0000,   3.5000,   8.1700,   1.0000],\n",
            "        [307.0000, 108.0000,   2.0000,   4.0000,   3.5000,   7.7000,   0.0000],\n",
            "        [331.0000, 116.0000,   5.0000,   5.0000,   5.0000,   9.3800,   1.0000],\n",
            "        [320.0000, 104.0000,   3.0000,   3.0000,   2.5000,   8.5700,   1.0000],\n",
            "        [299.0000, 100.0000,   3.0000,   2.0000,   2.0000,   8.0200,   0.0000],\n",
            "        [303.0000, 100.0000,   2.0000,   3.0000,   3.5000,   8.0600,   1.0000],\n",
            "        [316.0000, 104.0000,   3.0000,   3.0000,   3.5000,   8.0000,   1.0000],\n",
            "        [300.0000, 100.0000,   3.0000,   3.0000,   3.5000,   8.2600,   0.0000]])\n",
            "tensor([0.6500, 0.5700, 0.7100, 0.6400, 0.7400, 0.7600, 0.8600, 0.4700, 0.7300,\n",
            "        0.4800, 0.9300, 0.7400, 0.6300, 0.6400, 0.7200, 0.6200])\n",
            "..................................................\n",
            "tensor([[317.0000, 110.0000,   3.0000,   4.0000,   4.5000,   9.1100,   1.0000],\n",
            "        [305.0000, 106.0000,   2.0000,   3.0000,   3.0000,   8.1600,   0.0000],\n",
            "        [326.0000, 114.0000,   3.0000,   3.0000,   3.0000,   9.1100,   1.0000],\n",
            "        [314.0000, 107.0000,   2.0000,   2.5000,   4.0000,   8.2700,   0.0000],\n",
            "        [311.0000, 102.0000,   3.0000,   4.5000,   4.0000,   8.6400,   1.0000],\n",
            "        [328.0000, 108.0000,   4.0000,   4.5000,   4.0000,   9.1800,   1.0000],\n",
            "        [326.0000, 113.0000,   5.0000,   4.5000,   4.0000,   9.4000,   1.0000],\n",
            "        [325.0000, 106.0000,   3.0000,   3.5000,   4.0000,   8.4000,   1.0000],\n",
            "        [310.0000, 103.0000,   2.0000,   2.5000,   2.5000,   8.2400,   0.0000],\n",
            "        [301.0000, 104.0000,   3.0000,   3.5000,   4.0000,   8.1200,   1.0000],\n",
            "        [308.0000, 108.0000,   4.0000,   4.5000,   5.0000,   8.3400,   0.0000],\n",
            "        [317.0000, 105.0000,   3.0000,   3.5000,   3.0000,   8.5600,   0.0000],\n",
            "        [330.0000, 114.0000,   4.0000,   4.5000,   3.0000,   9.1700,   1.0000],\n",
            "        [314.0000, 105.0000,   2.0000,   2.5000,   2.0000,   7.6400,   0.0000],\n",
            "        [340.0000, 120.0000,   4.0000,   4.5000,   4.0000,   9.9200,   1.0000],\n",
            "        [297.0000,  96.0000,   2.0000,   2.5000,   1.5000,   7.8900,   0.0000]])\n",
            "tensor([0.8000, 0.6400, 0.8300, 0.7200, 0.6800, 0.8400, 0.9100, 0.5200, 0.7200,\n",
            "        0.6800, 0.7700, 0.6800, 0.8600, 0.7000, 0.9700, 0.4300])\n",
            "..................................................\n",
            "tensor([[329.0000, 114.0000,   2.0000,   2.0000,   4.0000,   8.5600,   1.0000],\n",
            "        [326.0000, 110.0000,   3.0000,   3.5000,   3.5000,   8.7600,   1.0000],\n",
            "        [305.0000, 102.0000,   2.0000,   2.0000,   2.5000,   8.1800,   0.0000],\n",
            "        [332.0000, 119.0000,   4.0000,   5.0000,   4.5000,   9.2400,   1.0000],\n",
            "        [311.0000,  99.0000,   2.0000,   2.5000,   3.0000,   7.9800,   0.0000],\n",
            "        [312.0000, 107.0000,   3.0000,   3.0000,   2.0000,   7.9000,   1.0000],\n",
            "        [314.0000, 102.0000,   2.0000,   2.0000,   2.5000,   8.2400,   0.0000],\n",
            "        [325.0000, 111.0000,   4.0000,   4.0000,   4.5000,   9.1100,   1.0000],\n",
            "        [323.0000, 112.0000,   5.0000,   4.0000,   4.5000,   8.7800,   0.0000],\n",
            "        [301.0000, 100.0000,   3.0000,   3.5000,   3.0000,   8.0400,   0.0000],\n",
            "        [313.0000, 109.0000,   3.0000,   4.0000,   3.5000,   9.0000,   0.0000],\n",
            "        [314.0000, 110.0000,   3.0000,   4.0000,   4.0000,   8.8000,   0.0000],\n",
            "        [302.0000, 102.0000,   3.0000,   3.5000,   5.0000,   8.3300,   0.0000],\n",
            "        [328.0000, 115.0000,   4.0000,   4.5000,   4.0000,   9.1600,   1.0000],\n",
            "        [329.0000, 111.0000,   4.0000,   4.5000,   4.0000,   9.2300,   1.0000],\n",
            "        [324.0000, 111.0000,   3.0000,   2.5000,   1.5000,   8.7900,   1.0000]])\n",
            "tensor([0.7200, 0.7900, 0.6200, 0.9000, 0.6500, 0.6400, 0.6400, 0.8300, 0.7900,\n",
            "        0.6700, 0.7900, 0.7500, 0.6500, 0.7800, 0.8900, 0.7000])\n",
            "..................................................\n",
            "tensor([[336.0000, 118.0000,   5.0000,   4.5000,   5.0000,   9.5300,   1.0000],\n",
            "        [321.0000, 111.0000,   5.0000,   5.0000,   5.0000,   9.4500,   1.0000],\n",
            "        [312.0000, 105.0000,   2.0000,   2.0000,   2.5000,   8.4500,   0.0000],\n",
            "        [338.0000, 118.0000,   4.0000,   3.0000,   4.5000,   9.4000,   1.0000],\n",
            "        [316.0000, 110.0000,   3.0000,   4.0000,   4.5000,   8.7800,   1.0000],\n",
            "        [305.0000, 112.0000,   3.0000,   3.0000,   3.5000,   8.6500,   0.0000],\n",
            "        [318.0000, 100.0000,   2.0000,   2.5000,   3.5000,   8.5400,   1.0000],\n",
            "        [332.0000, 118.0000,   5.0000,   5.0000,   5.0000,   9.4700,   1.0000],\n",
            "        [327.0000, 113.0000,   4.0000,   3.5000,   3.0000,   8.6900,   1.0000],\n",
            "        [330.0000, 116.0000,   5.0000,   5.0000,   4.5000,   9.3600,   1.0000],\n",
            "        [321.0000, 110.0000,   3.0000,   3.5000,   5.0000,   8.8500,   1.0000],\n",
            "        [311.0000, 105.0000,   3.0000,   3.5000,   3.0000,   8.4500,   1.0000],\n",
            "        [328.0000, 116.0000,   5.0000,   5.0000,   5.0000,   9.5000,   1.0000],\n",
            "        [327.0000, 104.0000,   5.0000,   3.0000,   3.5000,   8.8400,   1.0000],\n",
            "        [333.0000, 119.0000,   5.0000,   5.0000,   4.5000,   9.7800,   1.0000],\n",
            "        [326.0000, 116.0000,   3.0000,   3.5000,   4.0000,   9.1400,   1.0000]])\n",
            "tensor([0.9400, 0.9300, 0.7200, 0.9100, 0.6900, 0.7100, 0.7100, 0.9400, 0.8000,\n",
            "        0.9300, 0.8200, 0.5900, 0.9400, 0.7100, 0.9600, 0.8100])\n",
            "..................................................\n",
            "tensor([[324.0000, 112.0000,   5.0000,   5.0000,   5.0000,   9.0800,   1.0000],\n",
            "        [322.0000, 112.0000,   4.0000,   4.5000,   4.5000,   9.2600,   1.0000],\n",
            "        [299.0000, 102.0000,   3.0000,   4.0000,   3.5000,   8.6200,   0.0000],\n",
            "        [324.0000, 105.0000,   3.0000,   3.0000,   4.0000,   8.7500,   0.0000],\n",
            "        [305.0000, 103.0000,   2.0000,   2.5000,   3.5000,   8.1300,   0.0000],\n",
            "        [301.0000,  98.0000,   1.0000,   2.0000,   3.0000,   8.0300,   1.0000],\n",
            "        [299.0000,  96.0000,   2.0000,   1.5000,   2.0000,   7.8600,   0.0000],\n",
            "        [317.0000, 107.0000,   3.0000,   3.5000,   3.0000,   8.6800,   1.0000],\n",
            "        [307.0000, 101.0000,   3.0000,   4.0000,   3.0000,   8.2000,   0.0000],\n",
            "        [308.0000, 103.0000,   2.0000,   2.5000,   4.0000,   8.3600,   1.0000],\n",
            "        [305.0000, 108.0000,   5.0000,   3.0000,   3.0000,   8.4800,   0.0000],\n",
            "        [332.0000, 116.0000,   5.0000,   5.0000,   5.0000,   9.2800,   1.0000],\n",
            "        [329.0000, 119.0000,   4.0000,   4.5000,   4.5000,   9.1600,   1.0000],\n",
            "        [319.0000, 105.0000,   3.0000,   3.0000,   3.5000,   8.6700,   1.0000],\n",
            "        [322.0000, 107.0000,   3.0000,   3.5000,   3.5000,   8.4600,   1.0000],\n",
            "        [323.0000, 113.0000,   3.0000,   4.0000,   4.0000,   8.8800,   1.0000]])\n",
            "tensor([0.8800, 0.9100, 0.5600, 0.7900, 0.5900, 0.6700, 0.5400, 0.8400, 0.4700,\n",
            "        0.7000, 0.6100, 0.9400, 0.9000, 0.7300, 0.7100, 0.7900])\n",
            "..................................................\n",
            "tensor([[320.0000, 113.0000,   2.0000,   2.0000,   2.5000,   8.6400,   1.0000],\n",
            "        [322.0000, 110.0000,   3.0000,   3.5000,   2.5000,   8.6700,   1.0000],\n",
            "        [304.0000, 102.0000,   2.0000,   3.0000,   4.0000,   8.7300,   0.0000],\n",
            "        [313.0000, 102.0000,   3.0000,   2.5000,   2.5000,   8.6800,   0.0000],\n",
            "        [329.0000, 114.0000,   5.0000,   4.0000,   5.0000,   9.3000,   1.0000],\n",
            "        [313.0000, 104.0000,   3.0000,   4.0000,   4.5000,   8.6500,   0.0000],\n",
            "        [316.0000,  99.0000,   2.0000,   2.5000,   3.0000,   9.0000,   0.0000],\n",
            "        [298.0000, 101.0000,   2.0000,   1.5000,   2.0000,   7.8600,   0.0000],\n",
            "        [339.0000, 116.0000,   4.0000,   4.0000,   3.5000,   9.8000,   1.0000],\n",
            "        [312.0000, 108.0000,   3.0000,   3.5000,   3.0000,   8.5300,   0.0000],\n",
            "        [303.0000,  99.0000,   3.0000,   2.0000,   2.5000,   7.6600,   0.0000],\n",
            "        [312.0000, 101.0000,   2.0000,   2.5000,   3.5000,   8.0400,   1.0000],\n",
            "        [323.0000, 110.0000,   3.0000,   4.0000,   3.5000,   9.1000,   1.0000],\n",
            "        [307.0000, 109.0000,   3.0000,   4.0000,   3.0000,   8.0000,   1.0000],\n",
            "        [314.0000, 104.0000,   4.0000,   5.0000,   5.0000,   9.0200,   0.0000],\n",
            "        [315.0000, 100.0000,   1.0000,   2.0000,   2.5000,   7.9500,   0.0000]])\n",
            "tensor([0.8100, 0.8000, 0.6700, 0.7100, 0.8600, 0.7300, 0.7000, 0.5400, 0.9600,\n",
            "        0.6900, 0.3600, 0.6800, 0.7900, 0.6200, 0.8200, 0.5800])\n",
            "..................................................\n",
            "tensor([[312.0000, 107.0000,   3.0000,   3.0000,   3.0000,   8.4600,   1.0000],\n",
            "        [304.0000, 105.0000,   1.0000,   3.0000,   1.5000,   7.5000,   0.0000],\n",
            "        [334.0000, 120.0000,   5.0000,   4.0000,   5.0000,   9.8700,   1.0000],\n",
            "        [309.0000, 108.0000,   3.0000,   2.5000,   3.0000,   8.1200,   0.0000],\n",
            "        [306.0000, 110.0000,   2.0000,   3.5000,   4.0000,   8.4500,   0.0000],\n",
            "        [304.0000, 101.0000,   2.0000,   2.0000,   2.5000,   7.6600,   0.0000],\n",
            "        [315.0000, 105.0000,   2.0000,   2.0000,   2.5000,   7.6500,   0.0000],\n",
            "        [334.0000, 119.0000,   5.0000,   5.0000,   4.5000,   9.7000,   1.0000],\n",
            "        [330.0000, 114.0000,   3.0000,   4.5000,   4.5000,   9.2400,   1.0000],\n",
            "        [325.0000, 110.0000,   4.0000,   3.5000,   4.0000,   8.6700,   1.0000],\n",
            "        [331.0000, 119.0000,   4.0000,   5.0000,   4.5000,   9.3400,   1.0000],\n",
            "        [324.0000, 100.0000,   3.0000,   4.0000,   5.0000,   8.6400,   1.0000],\n",
            "        [325.0000, 110.0000,   2.0000,   3.0000,   2.5000,   8.7600,   1.0000],\n",
            "        [317.0000, 104.0000,   2.0000,   3.0000,   3.0000,   8.7600,   0.0000],\n",
            "        [319.0000, 110.0000,   3.0000,   3.0000,   2.5000,   8.7900,   0.0000],\n",
            "        [334.0000, 116.0000,   4.0000,   4.0000,   3.0000,   8.0000,   1.0000]])\n",
            "tensor([0.7500, 0.5200, 0.9700, 0.7200, 0.6300, 0.3800, 0.3900, 0.9500, 0.9000,\n",
            "        0.7300, 0.9000, 0.7800, 0.7500, 0.7700, 0.7200, 0.7800])\n",
            "..................................................\n",
            "tensor([[305.0000, 107.0000,   2.0000,   2.5000,   2.5000,   8.4200,   0.0000],\n",
            "        [324.0000, 111.0000,   3.0000,   2.5000,   2.0000,   8.8000,   1.0000],\n",
            "        [307.0000, 110.0000,   4.0000,   4.0000,   4.5000,   8.3700,   0.0000],\n",
            "        [309.0000, 104.0000,   2.0000,   2.0000,   2.5000,   8.2600,   0.0000],\n",
            "        [320.0000, 101.0000,   2.0000,   2.5000,   3.0000,   8.6200,   0.0000],\n",
            "        [333.0000, 113.0000,   5.0000,   4.0000,   4.0000,   9.2800,   1.0000],\n",
            "        [301.0000, 104.0000,   2.0000,   3.5000,   3.5000,   7.8900,   1.0000],\n",
            "        [320.0000, 110.0000,   2.0000,   4.0000,   3.5000,   8.5600,   0.0000],\n",
            "        [331.0000, 115.0000,   5.0000,   4.0000,   3.5000,   9.4400,   1.0000],\n",
            "        [312.0000, 107.0000,   2.0000,   2.5000,   3.5000,   8.2700,   0.0000],\n",
            "        [323.0000, 113.0000,   3.0000,   4.0000,   3.0000,   9.3200,   1.0000],\n",
            "        [307.0000, 107.0000,   2.0000,   3.0000,   3.5000,   8.5200,   1.0000],\n",
            "        [290.0000, 100.0000,   1.0000,   1.5000,   2.0000,   7.5600,   0.0000],\n",
            "        [300.0000, 105.0000,   1.0000,   1.0000,   2.0000,   7.8000,   0.0000],\n",
            "        [325.0000, 108.0000,   4.0000,   4.5000,   4.0000,   9.0600,   1.0000],\n",
            "        [301.0000,  97.0000,   2.0000,   3.0000,   3.0000,   7.8800,   1.0000]])\n",
            "tensor([0.7100, 0.7900, 0.7900, 0.6500, 0.7000, 0.8900, 0.6800, 0.7200, 0.9200,\n",
            "        0.6900, 0.8500, 0.7800, 0.4700, 0.5800, 0.7900, 0.4400])\n",
            "..................................................\n",
            "tensor([[325.0000, 111.0000,   3.0000,   3.0000,   3.5000,   8.7000,   0.0000],\n",
            "        [306.0000, 105.0000,   2.0000,   3.0000,   2.5000,   8.2600,   0.0000],\n",
            "        [320.0000, 111.0000,   4.0000,   4.5000,   3.5000,   8.8700,   1.0000],\n",
            "        [320.0000, 110.0000,   5.0000,   5.0000,   5.0000,   9.2000,   1.0000],\n",
            "        [327.0000, 113.0000,   3.0000,   3.5000,   3.0000,   8.6600,   1.0000],\n",
            "        [334.0000, 119.0000,   5.0000,   4.5000,   4.5000,   9.4800,   1.0000],\n",
            "        [321.0000, 111.0000,   3.0000,   2.5000,   3.0000,   8.9000,   1.0000],\n",
            "        [299.0000, 106.0000,   2.0000,   4.0000,   4.0000,   8.4000,   0.0000],\n",
            "        [316.0000, 110.0000,   3.0000,   3.5000,   4.0000,   8.5600,   0.0000],\n",
            "        [317.0000, 106.0000,   3.0000,   4.0000,   3.5000,   8.5000,   1.0000],\n",
            "        [312.0000, 105.0000,   2.0000,   2.5000,   3.0000,   8.1200,   0.0000],\n",
            "        [320.0000, 110.0000,   5.0000,   5.0000,   4.5000,   9.2200,   1.0000],\n",
            "        [317.0000, 103.0000,   3.0000,   2.5000,   3.0000,   8.5400,   1.0000],\n",
            "        [333.0000, 117.0000,   4.0000,   5.0000,   4.0000,   9.6600,   1.0000],\n",
            "        [312.0000, 106.0000,   3.0000,   4.0000,   3.5000,   8.7900,   1.0000],\n",
            "        [322.0000, 115.0000,   5.0000,   4.0000,   4.5000,   9.3600,   1.0000]])\n",
            "tensor([0.5200, 0.7300, 0.8500, 0.8800, 0.8000, 0.9400, 0.8000, 0.6400, 0.7500,\n",
            "        0.7500, 0.6400, 0.9200, 0.7300, 0.9500, 0.8100, 0.9200])\n",
            "..................................................\n",
            "tensor([[309.0000, 100.0000,   2.0000,   3.0000,   3.0000,   8.1000,   0.0000],\n",
            "        [332.0000, 118.0000,   5.0000,   5.0000,   5.0000,   9.6400,   1.0000],\n",
            "        [329.0000, 114.0000,   5.0000,   4.5000,   5.0000,   9.1900,   1.0000],\n",
            "        [327.0000, 108.0000,   5.0000,   5.0000,   3.5000,   9.1300,   1.0000],\n",
            "        [309.0000, 106.0000,   2.0000,   2.5000,   2.5000,   8.0000,   0.0000],\n",
            "        [327.0000, 113.0000,   4.0000,   4.5000,   4.5000,   9.1100,   1.0000],\n",
            "        [318.0000, 109.0000,   3.0000,   3.5000,   4.0000,   9.2200,   1.0000],\n",
            "        [326.0000, 108.0000,   3.0000,   3.0000,   3.5000,   8.8900,   0.0000],\n",
            "        [323.0000, 108.0000,   3.0000,   3.5000,   3.0000,   8.6000,   0.0000],\n",
            "        [322.0000, 114.0000,   5.0000,   4.5000,   4.0000,   8.9400,   1.0000],\n",
            "        [328.0000, 110.0000,   4.0000,   5.0000,   4.0000,   9.1400,   1.0000],\n",
            "        [327.0000, 114.0000,   3.0000,   3.0000,   3.0000,   9.0200,   0.0000],\n",
            "        [302.0000, 102.0000,   1.0000,   2.0000,   1.5000,   8.0000,   0.0000],\n",
            "        [312.0000, 104.0000,   3.0000,   3.5000,   3.5000,   8.4200,   0.0000],\n",
            "        [327.0000, 103.0000,   3.0000,   4.0000,   4.0000,   8.3000,   1.0000],\n",
            "        [332.0000, 118.0000,   2.0000,   4.5000,   3.5000,   9.3600,   1.0000]])\n",
            "tensor([0.4800, 0.9400, 0.8600, 0.8700, 0.6200, 0.8900, 0.6800, 0.8000, 0.4500,\n",
            "        0.8600, 0.8200, 0.6100, 0.5000, 0.7400, 0.7400, 0.9000])\n",
            "..................................................\n",
            "tensor([[337.0000, 118.0000,   4.0000,   4.5000,   4.5000,   9.6500,   1.0000],\n",
            "        [335.0000, 117.0000,   5.0000,   5.0000,   5.0000,   9.5600,   1.0000],\n",
            "        [314.0000, 108.0000,   3.0000,   4.5000,   3.5000,   8.1400,   0.0000],\n",
            "        [303.0000, 102.0000,   3.0000,   3.5000,   3.0000,   8.5000,   0.0000],\n",
            "        [319.0000, 106.0000,   3.0000,   3.5000,   2.5000,   8.3300,   1.0000],\n",
            "        [340.0000, 114.0000,   5.0000,   4.0000,   4.0000,   9.6000,   1.0000],\n",
            "        [321.0000, 107.0000,   2.0000,   2.0000,   1.5000,   8.4400,   0.0000],\n",
            "        [322.0000, 110.0000,   3.0000,   3.0000,   3.5000,   8.0000,   0.0000],\n",
            "        [323.0000, 108.0000,   5.0000,   4.0000,   4.0000,   8.7400,   1.0000],\n",
            "        [339.0000, 119.0000,   5.0000,   4.5000,   4.0000,   9.7000,   0.0000],\n",
            "        [315.0000, 105.0000,   3.0000,   2.0000,   2.5000,   8.4800,   0.0000],\n",
            "        [316.0000,  98.0000,   1.0000,   1.5000,   2.0000,   7.4300,   0.0000],\n",
            "        [328.0000, 110.0000,   4.0000,   4.0000,   2.5000,   9.0200,   1.0000],\n",
            "        [321.0000, 111.0000,   3.0000,   3.5000,   4.0000,   8.8300,   1.0000],\n",
            "        [308.0000, 108.0000,   3.0000,   3.5000,   3.5000,   8.2200,   0.0000],\n",
            "        [322.0000, 109.0000,   5.0000,   4.5000,   3.5000,   8.8000,   0.0000]])\n",
            "tensor([0.9200, 0.9400, 0.6400, 0.6200, 0.7400, 0.9000, 0.8100, 0.7000, 0.8100,\n",
            "        0.8900, 0.7500, 0.4900, 0.8100, 0.7700, 0.6100, 0.7600])\n",
            "..................................................\n",
            "tensor([[325.0000, 107.0000,   3.0000,   3.0000,   3.5000,   9.1100,   1.0000],\n",
            "        [326.0000, 116.0000,   2.0000,   4.5000,   3.0000,   9.0800,   1.0000],\n",
            "        [311.0000, 104.0000,   2.0000,   2.5000,   3.5000,   8.4800,   0.0000],\n",
            "        [324.0000, 110.0000,   3.0000,   3.5000,   4.0000,   8.8700,   1.0000],\n",
            "        [307.0000, 102.0000,   3.0000,   3.0000,   3.0000,   8.2700,   0.0000],\n",
            "        [311.0000, 104.0000,   3.0000,   4.5000,   4.5000,   8.4300,   0.0000],\n",
            "        [315.0000, 103.0000,   1.0000,   1.5000,   2.0000,   7.8600,   0.0000],\n",
            "        [313.0000, 106.0000,   2.0000,   2.5000,   2.0000,   8.4300,   0.0000],\n",
            "        [319.0000, 112.0000,   3.0000,   2.5000,   2.0000,   8.7100,   1.0000],\n",
            "        [324.0000, 110.0000,   3.0000,   3.5000,   3.5000,   9.0400,   1.0000],\n",
            "        [293.0000,  97.0000,   2.0000,   2.0000,   4.0000,   7.8000,   1.0000],\n",
            "        [335.0000, 115.0000,   4.0000,   4.5000,   4.5000,   9.6800,   1.0000],\n",
            "        [313.0000, 101.0000,   3.0000,   2.5000,   3.0000,   8.0400,   0.0000],\n",
            "        [315.0000, 107.0000,   2.0000,   4.0000,   3.0000,   8.5000,   1.0000],\n",
            "        [308.0000, 110.0000,   3.0000,   3.5000,   3.0000,   8.0000,   1.0000],\n",
            "        [322.0000, 110.0000,   5.0000,   5.0000,   4.0000,   9.1000,   1.0000]])\n",
            "tensor([0.8400, 0.8000, 0.7100, 0.8000, 0.7300, 0.7000, 0.5700, 0.6200, 0.7800,\n",
            "        0.8200, 0.6400, 0.9300, 0.6200, 0.5600, 0.4600, 0.8800])\n",
            "..................................................\n",
            "tensor([[306.0000, 100.0000,   2.0000,   3.0000,   3.0000,   8.0000,   0.0000],\n",
            "        [340.0000, 115.0000,   5.0000,   4.5000,   4.5000,   9.4500,   1.0000],\n",
            "        [296.0000,  97.0000,   2.0000,   1.5000,   2.0000,   7.8000,   0.0000],\n",
            "        [322.0000, 105.0000,   2.0000,   3.0000,   3.0000,   8.4500,   1.0000],\n",
            "        [296.0000, 101.0000,   1.0000,   2.5000,   3.0000,   7.6800,   0.0000],\n",
            "        [311.0000,  99.0000,   1.0000,   2.5000,   3.0000,   8.4300,   1.0000],\n",
            "        [319.0000, 110.0000,   3.0000,   3.5000,   3.5000,   9.0400,   0.0000],\n",
            "        [311.0000,  98.0000,   1.0000,   1.0000,   2.5000,   7.4600,   0.0000],\n",
            "        [313.0000, 107.0000,   2.0000,   2.5000,   2.0000,   8.5000,   1.0000],\n",
            "        [317.0000, 100.0000,   2.0000,   3.0000,   2.5000,   8.5700,   0.0000],\n",
            "        [312.0000,  99.0000,   1.0000,   1.0000,   1.5000,   8.0100,   1.0000],\n",
            "        [319.0000, 108.0000,   3.0000,   3.0000,   3.5000,   8.5400,   1.0000],\n",
            "        [335.0000, 118.0000,   5.0000,   4.5000,   3.5000,   9.4400,   1.0000],\n",
            "        [308.0000, 110.0000,   4.0000,   3.5000,   3.0000,   8.6000,   0.0000],\n",
            "        [302.0000,  99.0000,   1.0000,   2.0000,   2.0000,   7.2500,   0.0000],\n",
            "        [298.0000,  92.0000,   1.0000,   2.0000,   2.0000,   7.8800,   0.0000]])\n",
            "tensor([0.4800, 0.9400, 0.4900, 0.6500, 0.6000, 0.7100, 0.8200, 0.5700, 0.5300,\n",
            "        0.6800, 0.5200, 0.7100, 0.9300, 0.7000, 0.5700, 0.5100])\n",
            "..................................................\n",
            "tensor([[324.0000, 114.0000,   5.0000,   5.0000,   4.5000,   9.0800,   1.0000],\n",
            "        [302.0000, 101.0000,   2.0000,   2.5000,   3.5000,   7.9600,   0.0000],\n",
            "        [306.0000, 103.0000,   2.0000,   2.5000,   3.0000,   8.3600,   0.0000],\n",
            "        [313.0000, 102.0000,   3.0000,   3.5000,   4.0000,   8.9000,   1.0000],\n",
            "        [298.0000,  98.0000,   2.0000,   1.5000,   2.5000,   7.5000,   1.0000],\n",
            "        [303.0000, 105.0000,   5.0000,   5.0000,   4.5000,   8.6500,   0.0000],\n",
            "        [295.0000,  93.0000,   1.0000,   2.0000,   2.0000,   7.2000,   0.0000],\n",
            "        [312.0000, 100.0000,   2.0000,   1.5000,   3.5000,   7.9000,   1.0000],\n",
            "        [317.0000, 106.0000,   2.0000,   2.0000,   3.5000,   8.1200,   0.0000],\n",
            "        [318.0000, 109.0000,   3.0000,   3.0000,   3.0000,   8.5000,   0.0000],\n",
            "        [323.0000, 113.0000,   4.0000,   4.0000,   4.5000,   9.2300,   1.0000],\n",
            "        [316.0000, 102.0000,   3.0000,   2.0000,   3.0000,   7.4000,   0.0000],\n",
            "        [308.0000, 101.0000,   2.0000,   3.0000,   4.0000,   7.9000,   0.0000],\n",
            "        [296.0000,  99.0000,   2.0000,   3.0000,   3.5000,   7.2800,   0.0000],\n",
            "        [321.0000, 109.0000,   4.0000,   4.0000,   4.0000,   8.6800,   1.0000],\n",
            "        [326.0000, 112.0000,   3.0000,   3.5000,   3.0000,   9.1000,   1.0000]])\n",
            "tensor([0.8900, 0.4600, 0.6900, 0.7700, 0.4400, 0.7700, 0.4600, 0.5600, 0.7300,\n",
            "        0.6700, 0.8900, 0.6400, 0.6800, 0.4700, 0.6900, 0.8400])\n",
            "..................................................\n",
            "tensor([[294.0000,  93.0000,   1.0000,   1.5000,   2.0000,   7.3600,   0.0000],\n",
            "        [317.0000, 103.0000,   2.0000,   2.5000,   2.0000,   8.1500,   0.0000],\n",
            "        [316.0000, 106.0000,   2.0000,   2.5000,   4.0000,   8.3200,   0.0000],\n",
            "        [314.0000, 105.0000,   3.0000,   3.5000,   2.5000,   8.3000,   0.0000],\n",
            "        [313.0000,  98.0000,   3.0000,   2.5000,   4.5000,   8.3000,   1.0000],\n",
            "        [338.0000, 120.0000,   4.0000,   5.0000,   5.0000,   9.6600,   1.0000],\n",
            "        [338.0000, 115.0000,   5.0000,   4.5000,   5.0000,   9.2300,   1.0000],\n",
            "        [325.0000, 114.0000,   4.0000,   3.0000,   2.0000,   8.4000,   0.0000],\n",
            "        [333.0000, 118.0000,   5.0000,   5.0000,   5.0000,   9.3500,   1.0000],\n",
            "        [318.0000, 106.0000,   2.0000,   4.0000,   4.0000,   7.9200,   1.0000],\n",
            "        [301.0000, 106.0000,   4.0000,   2.5000,   3.0000,   8.4700,   0.0000],\n",
            "        [297.0000,  96.0000,   2.0000,   2.5000,   2.0000,   7.4300,   0.0000],\n",
            "        [313.0000, 103.0000,   3.0000,   4.0000,   4.0000,   8.7500,   0.0000],\n",
            "        [316.0000, 101.0000,   2.0000,   2.5000,   2.0000,   8.3200,   1.0000],\n",
            "        [310.0000, 106.0000,   4.0000,   4.5000,   4.5000,   9.0400,   1.0000],\n",
            "        [311.0000, 104.0000,   2.0000,   2.0000,   2.0000,   8.3000,   0.0000]])\n",
            "tensor([0.4600, 0.6500, 0.7200, 0.5400, 0.7600, 0.9500, 0.9100, 0.7000, 0.9200,\n",
            "        0.6400, 0.5700, 0.3400, 0.7600, 0.6100, 0.6600, 0.4200])\n",
            "..................................................\n",
            "tensor([[299.0000, 100.0000,   2.0000,   3.0000,   3.5000,   7.8800,   0.0000],\n",
            "        [323.0000, 110.0000,   5.0000,   4.0000,   5.0000,   8.9800,   1.0000],\n",
            "        [298.0000,  99.0000,   2.0000,   4.0000,   2.0000,   7.6000,   0.0000],\n",
            "        [304.0000, 103.0000,   5.0000,   5.0000,   4.0000,   8.6400,   0.0000],\n",
            "        [320.0000, 103.0000,   3.0000,   3.0000,   3.0000,   7.7000,   0.0000],\n",
            "        [303.0000,  98.0000,   1.0000,   2.0000,   2.5000,   7.6500,   0.0000],\n",
            "        [332.0000, 117.0000,   4.0000,   4.5000,   4.0000,   9.1000,   0.0000],\n",
            "        [306.0000, 106.0000,   2.0000,   2.0000,   2.5000,   8.1400,   0.0000],\n",
            "        [314.0000, 108.0000,   4.0000,   4.5000,   4.0000,   9.0400,   1.0000],\n",
            "        [313.0000, 107.0000,   3.0000,   4.0000,   4.5000,   8.6900,   0.0000],\n",
            "        [334.0000, 114.0000,   4.0000,   4.0000,   4.0000,   9.4300,   1.0000],\n",
            "        [326.0000, 112.0000,   3.0000,   3.5000,   3.0000,   9.0500,   1.0000],\n",
            "        [321.0000, 109.0000,   4.0000,   4.0000,   4.0000,   9.1300,   1.0000],\n",
            "        [321.0000, 109.0000,   3.0000,   3.5000,   3.5000,   8.8000,   1.0000],\n",
            "        [321.0000, 112.0000,   5.0000,   5.0000,   5.0000,   9.0600,   1.0000],\n",
            "        [321.0000, 109.0000,   3.0000,   3.0000,   3.0000,   8.5400,   1.0000]])\n",
            "tensor([0.6800, 0.8700, 0.4600, 0.6800, 0.6400, 0.5600, 0.8700, 0.6100, 0.8400,\n",
            "        0.7200, 0.9300, 0.7400, 0.8500, 0.7400, 0.8600, 0.7900])\n",
            "..................................................\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Defining our model using Pytorch\n",
        "import torch.nn as nn\n",
        "\n",
        "class Model(nn.Module):\n",
        "\n",
        "  def __init__(self,input_features):\n",
        "    super().__init__()\n",
        "    self.layers=nn.Sequential(\n",
        "        nn.Linear(input_features,out_features=5),\n",
        "        nn.ReLU(),\n",
        "        nn.Linear(in_features=5,out_features=1),\n",
        "\n",
        "    )\n",
        "\n",
        "  def forward(self,features):\n",
        "      return self.layers(features)"
      ],
      "metadata": {
        "id": "QFFbB0RJRxV-"
      },
      "id": "QFFbB0RJRxV-",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Important Parameters\n",
        "learning_rate = 0.1\n",
        "epochs = 25\n",
        "loss_function = nn.MSELoss()\n"
      ],
      "metadata": {
        "id": "HM6ekonyvb6j"
      },
      "id": "HM6ekonyvb6j",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Training Pipeline"
      ],
      "metadata": {
        "id": "RHWaiAlowDYx"
      },
      "id": "RHWaiAlowDYx"
    },
    {
      "cell_type": "code",
      "source": [
        "model = Model(X_train_tensor.shape[1])\n",
        "y_pred=model(X_train_tensor)\n",
        "y_pred"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "gsFcVDz-z71X",
        "outputId": "c0393947-4b23-4fe2-f57e-d03b082b6f19"
      },
      "id": "gsFcVDz-z71X",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[15.6831],\n",
              "        [18.6850],\n",
              "        [17.6249],\n",
              "        [17.0455],\n",
              "        [16.7644],\n",
              "        [16.2680],\n",
              "        [16.9612],\n",
              "        [18.6808],\n",
              "        [17.2819],\n",
              "        [17.8504],\n",
              "        [16.2059],\n",
              "        [17.1273],\n",
              "        [17.7600],\n",
              "        [17.3385],\n",
              "        [16.0252],\n",
              "        [16.9690],\n",
              "        [16.6276],\n",
              "        [17.3196],\n",
              "        [17.3302],\n",
              "        [17.8756],\n",
              "        [17.4352],\n",
              "        [16.1730],\n",
              "        [16.5136],\n",
              "        [15.9109],\n",
              "        [17.2454],\n",
              "        [17.3369],\n",
              "        [17.1257],\n",
              "        [16.2129],\n",
              "        [17.9604],\n",
              "        [16.8825],\n",
              "        [17.1043],\n",
              "        [16.0675],\n",
              "        [18.5402],\n",
              "        [17.1716],\n",
              "        [17.1240],\n",
              "        [15.5068],\n",
              "        [17.1364],\n",
              "        [17.5305],\n",
              "        [17.1083],\n",
              "        [17.5663],\n",
              "        [16.9066],\n",
              "        [16.7232],\n",
              "        [16.1785],\n",
              "        [17.4666],\n",
              "        [17.5813],\n",
              "        [16.8899],\n",
              "        [18.4450],\n",
              "        [17.8184],\n",
              "        [17.4521],\n",
              "        [18.3986],\n",
              "        [17.2778],\n",
              "        [15.8586],\n",
              "        [16.6796],\n",
              "        [17.9170],\n",
              "        [16.8990],\n",
              "        [16.4211],\n",
              "        [17.0552],\n",
              "        [16.6609],\n",
              "        [17.0223],\n",
              "        [15.6405],\n",
              "        [16.6648],\n",
              "        [17.4698],\n",
              "        [17.1080],\n",
              "        [18.0914],\n",
              "        [17.3531],\n",
              "        [16.3449],\n",
              "        [16.8299],\n",
              "        [17.3773],\n",
              "        [17.8534],\n",
              "        [17.1323],\n",
              "        [16.4951],\n",
              "        [18.6116],\n",
              "        [17.3303],\n",
              "        [17.6802],\n",
              "        [17.4905],\n",
              "        [17.0754],\n",
              "        [18.5239],\n",
              "        [16.6342],\n",
              "        [18.1784],\n",
              "        [16.8546],\n",
              "        [16.9568],\n",
              "        [16.8030],\n",
              "        [15.9588],\n",
              "        [17.9534],\n",
              "        [16.3966],\n",
              "        [17.1264],\n",
              "        [16.7831],\n",
              "        [16.6927],\n",
              "        [17.5589],\n",
              "        [16.9001],\n",
              "        [15.7281],\n",
              "        [17.8234],\n",
              "        [17.9094],\n",
              "        [18.3990],\n",
              "        [17.9506],\n",
              "        [18.1241],\n",
              "        [17.0918],\n",
              "        [17.1358],\n",
              "        [17.9909],\n",
              "        [17.2986],\n",
              "        [17.5359],\n",
              "        [17.6478],\n",
              "        [17.3300],\n",
              "        [16.9621],\n",
              "        [17.5021],\n",
              "        [16.4229],\n",
              "        [18.3252],\n",
              "        [17.0075],\n",
              "        [16.3101],\n",
              "        [17.9511],\n",
              "        [15.8467],\n",
              "        [17.7853],\n",
              "        [17.5948],\n",
              "        [18.2569],\n",
              "        [16.1908],\n",
              "        [16.2035],\n",
              "        [15.3231],\n",
              "        [16.1122],\n",
              "        [18.3578],\n",
              "        [16.4610],\n",
              "        [18.0586],\n",
              "        [17.7871],\n",
              "        [16.0224],\n",
              "        [15.7115],\n",
              "        [16.8973],\n",
              "        [15.2544],\n",
              "        [16.6641],\n",
              "        [16.7356],\n",
              "        [17.6814],\n",
              "        [18.7846],\n",
              "        [16.3833],\n",
              "        [17.4561],\n",
              "        [16.7678],\n",
              "        [16.3010],\n",
              "        [17.5601],\n",
              "        [18.3435],\n",
              "        [17.0528],\n",
              "        [17.4176],\n",
              "        [17.1606],\n",
              "        [16.9344],\n",
              "        [16.8421],\n",
              "        [17.8381],\n",
              "        [18.1241],\n",
              "        [17.1238],\n",
              "        [18.2118],\n",
              "        [16.0875],\n",
              "        [16.5213],\n",
              "        [16.6893],\n",
              "        [16.8343],\n",
              "        [16.6874],\n",
              "        [16.5553],\n",
              "        [17.4636],\n",
              "        [16.1217],\n",
              "        [15.6584],\n",
              "        [16.8308],\n",
              "        [18.9173],\n",
              "        [17.4129],\n",
              "        [17.5817],\n",
              "        [16.7445],\n",
              "        [17.3848],\n",
              "        [17.2334],\n",
              "        [18.2004],\n",
              "        [16.8992],\n",
              "        [17.6625],\n",
              "        [18.1101],\n",
              "        [17.7023],\n",
              "        [17.0300],\n",
              "        [18.0318],\n",
              "        [16.4471],\n",
              "        [18.8815],\n",
              "        [18.2559],\n",
              "        [18.6500],\n",
              "        [17.0594],\n",
              "        [15.9415],\n",
              "        [18.0968],\n",
              "        [17.8199],\n",
              "        [16.3036],\n",
              "        [18.7700],\n",
              "        [18.2881],\n",
              "        [16.5665],\n",
              "        [18.5033],\n",
              "        [16.9979],\n",
              "        [17.4077],\n",
              "        [16.6592],\n",
              "        [16.7268],\n",
              "        [16.4814],\n",
              "        [16.2972],\n",
              "        [17.0753],\n",
              "        [18.6835],\n",
              "        [16.7755],\n",
              "        [15.8321],\n",
              "        [17.4064],\n",
              "        [16.3464],\n",
              "        [16.0002],\n",
              "        [17.5602],\n",
              "        [18.5520],\n",
              "        [17.4104],\n",
              "        [16.5751],\n",
              "        [16.0574],\n",
              "        [16.2190],\n",
              "        [16.6172],\n",
              "        [16.6092],\n",
              "        [18.3338],\n",
              "        [16.7728],\n",
              "        [16.2379],\n",
              "        [16.1932],\n",
              "        [18.6292],\n",
              "        [17.5398],\n",
              "        [18.5295],\n",
              "        [18.9676],\n",
              "        [17.6361],\n",
              "        [16.3074],\n",
              "        [17.0441],\n",
              "        [17.0119],\n",
              "        [16.1842],\n",
              "        [17.2807],\n",
              "        [16.1194],\n",
              "        [15.8179],\n",
              "        [17.4966],\n",
              "        [16.6438],\n",
              "        [17.3932],\n",
              "        [17.0378],\n",
              "        [16.3564],\n",
              "        [18.1338],\n",
              "        [16.7744],\n",
              "        [16.0611],\n",
              "        [17.8338],\n",
              "        [17.6892],\n",
              "        [16.8021],\n",
              "        [16.3675],\n",
              "        [16.7275],\n",
              "        [18.2569],\n",
              "        [16.5361],\n",
              "        [18.2551],\n",
              "        [18.5385],\n",
              "        [17.4049],\n",
              "        [18.2586],\n",
              "        [16.6235],\n",
              "        [16.9301],\n",
              "        [17.6726],\n",
              "        [17.0697],\n",
              "        [18.0386],\n",
              "        [16.2826],\n",
              "        [17.0833],\n",
              "        [16.2324],\n",
              "        [18.9228],\n",
              "        [16.9398],\n",
              "        [17.0176],\n",
              "        [16.6712],\n",
              "        [16.4327],\n",
              "        [16.3277],\n",
              "        [18.1603],\n",
              "        [17.4492],\n",
              "        [17.4096],\n",
              "        [16.4363],\n",
              "        [17.8709],\n",
              "        [16.9369],\n",
              "        [16.7249],\n",
              "        [15.8773],\n",
              "        [17.8321],\n",
              "        [17.1098],\n",
              "        [16.8631],\n",
              "        [17.2534],\n",
              "        [18.9300],\n",
              "        [16.7850],\n",
              "        [17.7976],\n",
              "        [16.8988],\n",
              "        [18.6186],\n",
              "        [16.4671],\n",
              "        [17.6448],\n",
              "        [17.2162],\n",
              "        [17.4794],\n",
              "        [17.8691],\n",
              "        [18.4646],\n",
              "        [16.3095],\n",
              "        [17.5240],\n",
              "        [15.2677],\n",
              "        [17.7502],\n",
              "        [15.9086],\n",
              "        [15.6960],\n",
              "        [18.7214],\n",
              "        [16.8334],\n",
              "        [17.4316],\n",
              "        [17.6914],\n",
              "        [17.5785],\n",
              "        [16.4556],\n",
              "        [16.3869],\n",
              "        [17.1809],\n",
              "        [16.1177],\n",
              "        [18.2298],\n",
              "        [16.1980],\n",
              "        [17.9743],\n",
              "        [16.2802],\n",
              "        [18.4151],\n",
              "        [16.8814],\n",
              "        [16.0500],\n",
              "        [16.7809],\n",
              "        [18.2558],\n",
              "        [17.3789],\n",
              "        [16.0902],\n",
              "        [17.1070],\n",
              "        [16.3794],\n",
              "        [16.3817],\n",
              "        [18.0148],\n",
              "        [17.9204],\n",
              "        [17.2512],\n",
              "        [17.3842],\n",
              "        [18.0476],\n",
              "        [17.9291],\n",
              "        [18.5026],\n",
              "        [17.7941],\n",
              "        [17.6672],\n",
              "        [17.8561],\n",
              "        [18.9275],\n",
              "        [16.8722],\n",
              "        [17.3016],\n",
              "        [17.5726],\n",
              "        [17.3194],\n",
              "        [17.7088],\n",
              "        [16.8525]], grad_fn=<AddmmBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#initialize a model\n",
        "model = Model(X_train_tensor.shape[1])\n",
        "\n",
        "#define optimizer\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
        "criterion = nn.MSELoss()\n",
        "train_loss=[]\n",
        "val_loss=[]\n",
        "for epoch in range(epochs):\n",
        "\n",
        "  for batch_x,batch_y in train_dataloader:\n",
        "\n",
        "    y_pred=model(batch_x)\n",
        "    loss=loss_function(y_pred,batch_y.unsqueeze(1))\n",
        "\n",
        "    #clear gradients\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    #backward pass\n",
        "    loss.backward()\n",
        "\n",
        "    #parameter update\n",
        "    optimizer.step()\n",
        "\n",
        "  # print loss in each epoch\n",
        "  model.eval()\n",
        "  with torch.no_grad():\n",
        "      y_val_pred = model(X_test_tensor)\n",
        "      valu_loss = criterion(y_val_pred.squeeze(), y_test_tensor)\n",
        "      val_loss.append(valu_loss.item())\n",
        "  train_loss.append(loss.item())\n",
        "  print(f'Epoch: {epoch + 1}, Loss: {loss.item():.4f}')\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dH-YiiVpRxZo",
        "outputId": "834048f4-4f82-458c-aae8-69565bd7fcd7"
      },
      "id": "dH-YiiVpRxZo",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 1, Loss: 94442896.0000\n",
            "Epoch: 2, Loss: 12560.0957\n",
            "Epoch: 3, Loss: 1.6483\n",
            "Epoch: 4, Loss: 0.0318\n",
            "Epoch: 5, Loss: 0.0142\n",
            "Epoch: 6, Loss: 0.0136\n",
            "Epoch: 7, Loss: 0.0146\n",
            "Epoch: 8, Loss: 0.0143\n",
            "Epoch: 9, Loss: 0.0252\n",
            "Epoch: 10, Loss: 0.0144\n",
            "Epoch: 11, Loss: 0.0189\n",
            "Epoch: 12, Loss: 0.0174\n",
            "Epoch: 13, Loss: 0.0183\n",
            "Epoch: 14, Loss: 0.0184\n",
            "Epoch: 15, Loss: 0.0267\n",
            "Epoch: 16, Loss: 0.0250\n",
            "Epoch: 17, Loss: 0.0196\n",
            "Epoch: 18, Loss: 0.0288\n",
            "Epoch: 19, Loss: 0.0169\n",
            "Epoch: 20, Loss: 0.0179\n",
            "Epoch: 21, Loss: 0.0250\n",
            "Epoch: 22, Loss: 0.0247\n",
            "Epoch: 23, Loss: 0.0246\n",
            "Epoch: 24, Loss: 0.0224\n",
            "Epoch: 25, Loss: 0.0227\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Model Testing & Evaluation"
      ],
      "metadata": {
        "id": "nTk0Acyzy_ap"
      },
      "id": "nTk0Acyzy_ap"
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Plot Training vs Validation loss ---\n",
        "plt.figure(figsize=(7, 5))\n",
        "plt.plot(train_loss, label='Training Loss')\n",
        "plt.plot(val_loss, label='Validation Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('MSE Loss')\n",
        "plt.title('Training vs Validation Loss')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "# --- Final Test Evaluation ---\n",
        "with torch.no_grad():\n",
        "    y_test_pred = model(X_test_tensor)\n",
        "    test_mse = torch.mean((y_test_pred.squeeze() - y_test_tensor) ** 2)\n",
        "    print(f\"\\nFinal Test MSE: {test_mse.item():.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 522
        },
        "id": "vaeCJ0NDRxiH",
        "outputId": "27843e1c-e30e-42ec-fb90-6f8b316a56b7"
      },
      "id": "vaeCJ0NDRxiH",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 700x500 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Final Test MSE: 0.0231\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(train_loss)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5oT67rJTRxlO",
        "outputId": "94ee9366-f51b-42b0-9511-845fe80bd01e"
      },
      "id": "5oT67rJTRxlO",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "25"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(val_loss)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DileDfOORxoF",
        "outputId": "af0e2040-d27a-464d-c983-b4fefaac9ce4"
      },
      "id": "DileDfOORxoF",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "25"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Using Optuna"
      ],
      "metadata": {
        "id": "wTIMXPFmuKBs"
      },
      "id": "wTIMXPFmuKBs"
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.optim as optim\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f\"Using device: {device}\")"
      ],
      "metadata": {
        "id": "_MHcuBq4vRg7",
        "outputId": "49720fd0-c795-45c7-f98a-b168d2038532",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "_MHcuBq4vRg7",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cpu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size=16\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, pin_memory=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, pin_memory=True)"
      ],
      "metadata": {
        "id": "aMVN98TjigPW"
      },
      "id": "aMVN98TjigPW",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class MyNN(nn.Module):\n",
        "\n",
        "  def __init__(self, input_dim, output_dim, num_hidden_layers, neurons_per_layer, dropout_rate):\n",
        "\n",
        "    super().__init__()\n",
        "\n",
        "    layers = []\n",
        "\n",
        "    for i in range(num_hidden_layers):\n",
        "\n",
        "      layers.append(nn.Linear(input_dim, neurons_per_layer))\n",
        "      layers.append(nn.BatchNorm1d(neurons_per_layer)) #to normalize the outputs of the previous layer\n",
        "      layers.append(nn.ReLU())\n",
        "      layers.append(nn.Dropout(dropout_rate))\n",
        "      input_dim = neurons_per_layer\n",
        "\n",
        "    layers.append(nn.Linear(neurons_per_layer, output_dim))\n",
        "\n",
        "    self.model = nn.Sequential(*layers)\n",
        "\n",
        "  def forward(self, x):\n",
        "\n",
        "    return self.model(x)"
      ],
      "metadata": {
        "id": "QyOKtwz5uJSN"
      },
      "id": "QyOKtwz5uJSN",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# objective function\n",
        "def objective(trial):\n",
        "\n",
        "  # next hyperparameter values from the search space\n",
        "  num_hidden_layers = trial.suggest_int(\"num_hidden_layers\", 1, 5)\n",
        "  neurons_per_layer = trial.suggest_int(\"neurons_per_layer\", 8, 128, step=8)\n",
        "  epochs = trial.suggest_int(\"epochs\", 10, 50, step=10)\n",
        "  learning_rate = trial.suggest_float(\"learning_rate\", 1e-5, 1e-1, log=True)\n",
        "  dropout_rate = trial.suggest_float(\"dropout_rate\", 0.1, 0.5, step=0.1)\n",
        "  batch_size = trial.suggest_categorical(\"batch_size\", [16, 32, 64, 128])\n",
        "  optimizer_name = trial.suggest_categorical(\"optimizer\", ['Adam', 'SGD', 'RMSprop'])\n",
        "  weight_decay = trial.suggest_float(\"weight_decay\", 1e-5, 1e-3, log=True)\n",
        "\n",
        "\n",
        "\n",
        "  # model init\n",
        "  input_dim = 7\n",
        "  output_dim = 1\n",
        "\n",
        "  model = MyNN(input_dim, output_dim, num_hidden_layers, neurons_per_layer, dropout_rate)\n",
        "  model.to(device)\n",
        "\n",
        "  # optimizer selection\n",
        "  criterion = nn.MSELoss()\n",
        "\n",
        "\n",
        "  if optimizer_name == 'Adam':\n",
        "    optimizer = optim.Adam(model.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
        "  elif optimizer_name == 'SGD':\n",
        "    optimizer = optim.SGD(model.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
        "  else:\n",
        "    optimizer = optim.RMSprop(model.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
        "\n",
        "  # training loop\n",
        "\n",
        "  for epoch in range(epochs):\n",
        "\n",
        "    for batch_features, batch_labels in train_loader:\n",
        "\n",
        "      # move data to gpu\n",
        "      batch_features, batch_labels = batch_features.to(device), batch_labels.to(device)\n",
        "\n",
        "      # forward pass\n",
        "      outputs = model(batch_features)\n",
        "\n",
        "      # calculate loss\n",
        "      loss = criterion(outputs, batch_labels.float())\n",
        "\n",
        "      # back pass\n",
        "      optimizer.zero_grad()\n",
        "      loss.backward()\n",
        "\n",
        "      # update grads\n",
        "      optimizer.step()\n",
        "\n",
        "\n",
        "  # evaluation\n",
        "  model.eval()\n",
        "  # evaluation on test data\n",
        "  total = 0\n",
        "  correct = 0\n",
        "\n",
        "  with torch.no_grad():\n",
        "      total_mse = 0.0\n",
        "      total_samples = 0\n",
        "\n",
        "      for batch_features, batch_labels in test_loader:\n",
        "          # Move data to device\n",
        "          batch_features = batch_features.to(device).float()\n",
        "          batch_labels = batch_labels.to(device).float()\n",
        "\n",
        "          # Forward pass\n",
        "          outputs = model(batch_features).squeeze()  # shape: [batch_size]\n",
        "\n",
        "          # Batch MSE\n",
        "          mse = torch.mean((outputs - batch_labels) ** 2)\n",
        "\n",
        "          # Accumulate weighted average\n",
        "          total_mse += mse.item() * batch_labels.size(0)\n",
        "          total_samples += batch_labels.size(0)\n",
        "\n",
        "      # Compute final average MSE\n",
        "      mse = total_mse / total_samples\n",
        "\n",
        "  return mse\n"
      ],
      "metadata": {
        "id": "1YgFxsGouQ67"
      },
      "id": "1YgFxsGouQ67",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install optuna"
      ],
      "metadata": {
        "id": "VBLlfXVz20kF",
        "outputId": "22c6d6a0-bbd2-4300-c4a0-999aeff80010",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "VBLlfXVz20kF",
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting optuna\n",
            "  Downloading optuna-4.5.0-py3-none-any.whl.metadata (17 kB)\n",
            "Requirement already satisfied: alembic>=1.5.0 in /usr/local/lib/python3.12/dist-packages (from optuna) (1.17.0)\n",
            "Collecting colorlog (from optuna)\n",
            "  Downloading colorlog-6.10.1-py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from optuna) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from optuna) (25.0)\n",
            "Requirement already satisfied: sqlalchemy>=1.4.2 in /usr/local/lib/python3.12/dist-packages (from optuna) (2.0.44)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from optuna) (4.67.1)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.12/dist-packages (from optuna) (6.0.3)\n",
            "Requirement already satisfied: Mako in /usr/local/lib/python3.12/dist-packages (from alembic>=1.5.0->optuna) (1.3.10)\n",
            "Requirement already satisfied: typing-extensions>=4.12 in /usr/local/lib/python3.12/dist-packages (from alembic>=1.5.0->optuna) (4.15.0)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.12/dist-packages (from sqlalchemy>=1.4.2->optuna) (3.2.4)\n",
            "Requirement already satisfied: MarkupSafe>=0.9.2 in /usr/local/lib/python3.12/dist-packages (from Mako->alembic>=1.5.0->optuna) (3.0.3)\n",
            "Downloading optuna-4.5.0-py3-none-any.whl (400 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m400.9/400.9 kB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading colorlog-6.10.1-py3-none-any.whl (11 kB)\n",
            "Installing collected packages: colorlog, optuna\n",
            "Successfully installed colorlog-6.10.1 optuna-4.5.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import optuna\n",
        "\n",
        "study = optuna.create_study(direction='minimize')# For classification use maximize"
      ],
      "metadata": {
        "id": "y9vpb8QNu3TT",
        "outputId": "dfef4497-ff21-4852-e7dd-41deb860451d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 349
        }
      },
      "id": "y9vpb8QNu3TT",
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'optuna'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-1080629431.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0moptuna\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mstudy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptuna\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_study\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdirection\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'minimize'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m# For classification use maximize\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'optuna'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "study.optimize(objective, n_trials=10)"
      ],
      "metadata": {
        "id": "tlCoJITIvbZa",
        "outputId": "f010a9ac-6300-4aa2-ddf6-6c99f37940c2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "tlCoJITIvbZa",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:666: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
            "  warnings.warn(warn_msg)\n",
            "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/loss.py:616: UserWarning: Using a target size (torch.Size([16])) that is different to the input size (torch.Size([16, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n",
            "[I 2025-10-21 17:40:50,760] Trial 0 finished with value: 0.11989339590072631 and parameters: {'num_hidden_layers': 1, 'neurons_per_layer': 64, 'epochs': 20, 'learning_rate': 0.00010469278816900571, 'dropout_rate': 0.4, 'batch_size': 64, 'optimizer': 'RMSprop', 'weight_decay': 0.0005209018985963696}. Best is trial 0 with value: 0.11989339590072631.\n",
            "[I 2025-10-21 17:40:55,131] Trial 1 finished with value: 0.1513366401195526 and parameters: {'num_hidden_layers': 4, 'neurons_per_layer': 104, 'epochs': 30, 'learning_rate': 1.1948837505539334e-05, 'dropout_rate': 0.30000000000000004, 'batch_size': 128, 'optimizer': 'Adam', 'weight_decay': 2.3652789038102915e-05}. Best is trial 0 with value: 0.11989339590072631.\n",
            "[I 2025-10-21 17:40:55,504] Trial 2 finished with value: 0.1160783439874649 and parameters: {'num_hidden_layers': 1, 'neurons_per_layer': 32, 'epochs': 10, 'learning_rate': 0.0019389208638251703, 'dropout_rate': 0.2, 'batch_size': 64, 'optimizer': 'SGD', 'weight_decay': 5.133786018768098e-05}. Best is trial 2 with value: 0.1160783439874649.\n",
            "[I 2025-10-21 17:40:57,527] Trial 3 finished with value: 0.6034774065017701 and parameters: {'num_hidden_layers': 5, 'neurons_per_layer': 8, 'epochs': 10, 'learning_rate': 4.9258566617025524e-05, 'dropout_rate': 0.1, 'batch_size': 64, 'optimizer': 'Adam', 'weight_decay': 8.0188945547598e-05}. Best is trial 2 with value: 0.1160783439874649.\n",
            "[I 2025-10-21 17:40:59,561] Trial 4 finished with value: 0.2234931170940399 and parameters: {'num_hidden_layers': 4, 'neurons_per_layer': 112, 'epochs': 10, 'learning_rate': 0.00016835704614465532, 'dropout_rate': 0.30000000000000004, 'batch_size': 64, 'optimizer': 'SGD', 'weight_decay': 0.0002663122823498605}. Best is trial 2 with value: 0.1160783439874649.\n",
            "[I 2025-10-21 17:41:06,363] Trial 5 finished with value: 0.031000008061528205 and parameters: {'num_hidden_layers': 4, 'neurons_per_layer': 104, 'epochs': 50, 'learning_rate': 0.010654762168722916, 'dropout_rate': 0.4, 'batch_size': 64, 'optimizer': 'SGD', 'weight_decay': 2.1080911106807955e-05}. Best is trial 5 with value: 0.031000008061528205.\n",
            "[I 2025-10-21 17:41:08,794] Trial 6 finished with value: 0.03649044223129749 and parameters: {'num_hidden_layers': 2, 'neurons_per_layer': 112, 'epochs': 40, 'learning_rate': 0.00037755637239801876, 'dropout_rate': 0.30000000000000004, 'batch_size': 16, 'optimizer': 'Adam', 'weight_decay': 1.6571346662566797e-05}. Best is trial 5 with value: 0.031000008061528205.\n",
            "[I 2025-10-21 17:41:09,748] Trial 7 finished with value: 0.028481145575642585 and parameters: {'num_hidden_layers': 2, 'neurons_per_layer': 48, 'epochs': 30, 'learning_rate': 0.07732188438602756, 'dropout_rate': 0.5, 'batch_size': 128, 'optimizer': 'SGD', 'weight_decay': 0.00016669853348821637}. Best is trial 7 with value: 0.028481145575642585.\n",
            "[I 2025-10-21 17:41:11,687] Trial 8 finished with value: 0.025345128402113913 and parameters: {'num_hidden_layers': 2, 'neurons_per_layer': 40, 'epochs': 50, 'learning_rate': 0.013520500005221946, 'dropout_rate': 0.30000000000000004, 'batch_size': 128, 'optimizer': 'SGD', 'weight_decay': 0.00013526252169090503}. Best is trial 8 with value: 0.025345128402113913.\n",
            "[I 2025-10-21 17:41:13,574] Trial 9 finished with value: 0.02348655164241791 and parameters: {'num_hidden_layers': 1, 'neurons_per_layer': 104, 'epochs': 40, 'learning_rate': 0.06842072611021881, 'dropout_rate': 0.2, 'batch_size': 128, 'optimizer': 'Adam', 'weight_decay': 0.00012516834008659183}. Best is trial 9 with value: 0.02348655164241791.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "study.best_value"
      ],
      "metadata": {
        "id": "0mJPbSufywIJ",
        "outputId": "7e18fab9-595a-42af-a7f0-9a576534b682",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "0mJPbSufywIJ",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.02348655164241791"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "study.best_params"
      ],
      "metadata": {
        "id": "X8MNLQ4vy35M",
        "outputId": "9f56dadd-c67d-48c0-8acc-9228f1c2d31e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "X8MNLQ4vy35M",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'num_hidden_layers': 1,\n",
              " 'neurons_per_layer': 104,\n",
              " 'epochs': 40,\n",
              " 'learning_rate': 0.06842072611021881,\n",
              " 'dropout_rate': 0.2,\n",
              " 'batch_size': 128,\n",
              " 'optimizer': 'Adam',\n",
              " 'weight_decay': 0.00012516834008659183}"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, random_split\n",
        "import optuna\n",
        "import numpy as np\n",
        "import random\n",
        "\n",
        "# ✅ Optional: set seeds for reproducibility\n",
        "torch.manual_seed(42) # Any random operations in PyTorch — like random weight initialization in neural networks, shuffling in DataLoader, or random tensor generation — will now produce the same output each time you run your script.\n",
        "np.random.seed(42) # All NumPy random operations (e.g., np.random.rand(), np.random.randint()) will become reproducible.\n",
        "random.seed(42) # Sets the random seed for Python’s built-in random module like random.random(), random.shuffle(), random.choice().\n",
        "\n",
        "# Example: assuming you already have train_dataset and test_dataset loaded\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "def objective(trial):\n",
        "\n",
        "    # --- Hyperparameter search space ---\n",
        "    num_hidden_layers = trial.suggest_int(\"num_hidden_layers\", 1, 5)\n",
        "    neurons_per_layer = trial.suggest_int(\"neurons_per_layer\", 8, 128, step=8)\n",
        "    epochs = trial.suggest_int(\"epochs\", 10, 50, step=10)\n",
        "    learning_rate = trial.suggest_float(\"learning_rate\", 1e-5, 1e-1, log=True)\n",
        "    dropout_rate = trial.suggest_float(\"dropout_rate\", 0.1, 0.5, step=0.1)\n",
        "    batch_size = trial.suggest_categorical(\"batch_size\", [16, 32, 64, 128])\n",
        "    optimizer_name = trial.suggest_categorical(\"optimizer\", ['Adam', 'SGD', 'RMSprop'])\n",
        "    weight_decay = trial.suggest_float(\"weight_decay\", 1e-5, 1e-3, log=True)\n",
        "\n",
        "    # --- Split training data into train + validation sets ---\n",
        "    val_ratio = 0.2\n",
        "    val_size = int(len(train_dataset) * val_ratio)\n",
        "    train_data, val_data = random_split(train_dataset, [len(train_dataset) - val_size, val_size])\n",
        "\n",
        "    # --- DataLoaders ---\n",
        "    train_loader = DataLoader(train_data, batch_size=batch_size, shuffle=True, pin_memory=True)\n",
        "    val_loader = DataLoader(val_data, batch_size=batch_size, shuffle=False, pin_memory=True)\n",
        "    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, pin_memory=True)\n",
        "\n",
        "    # --- Model initialization ---\n",
        "    input_dim = 7\n",
        "    output_dim = 1\n",
        "    model = MyNN(input_dim, output_dim, num_hidden_layers, neurons_per_layer, dropout_rate)\n",
        "    model.to(device)\n",
        "\n",
        "    # --- Loss and optimizer setup ---\n",
        "    criterion = nn.MSELoss()\n",
        "\n",
        "    if optimizer_name == 'Adam':\n",
        "        optimizer = optim.Adam(model.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
        "    elif optimizer_name == 'SGD':\n",
        "        optimizer = optim.SGD(model.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
        "    else:\n",
        "        optimizer = optim.RMSprop(model.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
        "\n",
        "    # --- Training loop ---\n",
        "    best_val_loss = float(\"inf\")\n",
        "    patience, patience_counter = 5, 0  # for early stopping\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "\n",
        "        model.train()\n",
        "        running_loss = 0.0\n",
        "\n",
        "        for batch_features, batch_labels in train_loader:\n",
        "            batch_features, batch_labels = batch_features.to(device), batch_labels.to(device)\n",
        "\n",
        "            optimizer.zero_grad()                         # clears all the gradients\n",
        "            preds = model(batch_features).squeeze()       # forward pass\n",
        "            loss = criterion(preds, batch_labels.float()) # compute the mean of the individual losses\n",
        "            loss.backward()                               # Compute gradients via backpropagation\n",
        "            optimizer.step()                              # Update weights using gradients\n",
        "\n",
        "            running_loss += loss.item()    # adding the loss of each batch, loss looks like tensor(2.3456), to get numerical we use loss.item()\n",
        "\n",
        "        # --- Validation phase ---\n",
        "        model.eval()\n",
        "        val_loss = 0.0\n",
        "        with torch.no_grad(): # disable gradient tracking / computation graph which are done by Autograd\n",
        "            for X_val, y_val in val_loader:\n",
        "                X_val, y_val = X_val.to(device), y_val.to(device)\n",
        "                preds = model(X_val).squeeze()\n",
        "                val_loss += criterion(preds, y_val.float()).item()\n",
        "\n",
        "        val_loss /= len(val_loader)\n",
        "        trial.report(val_loss, epoch)  # Optuna reporting for pruning\n",
        "\n",
        "        # --- Pruning unpromising trials ---\n",
        "        if trial.should_prune():\n",
        "            raise optuna.exceptions.TrialPruned()\n",
        "\n",
        "        # --- Early stopping ---\n",
        "        if val_loss < best_val_loss:\n",
        "            best_val_loss = val_loss\n",
        "            patience_counter = 0\n",
        "        else:\n",
        "            patience_counter += 1\n",
        "            if patience_counter >= patience:\n",
        "                break\n",
        "\n",
        "    # --- Final evaluation on test set ---\n",
        "    model.eval()\n",
        "    total_mse = 0.0\n",
        "    total_samples = 0\n",
        "    with torch.no_grad():\n",
        "        for X_test, y_test in test_loader:\n",
        "            X_test, y_test = X_test.to(device), y_test.to(device)\n",
        "            preds = model(X_test).squeeze()\n",
        "            mse = torch.mean((preds - y_test) ** 2)\n",
        "            total_mse += mse.item() * y_test.size(0)\n",
        "            total_samples += y_test.size(0)\n",
        "\n",
        "    final_mse = total_mse / total_samples\n",
        "    torch.cuda.empty_cache()  # free GPU memory for next trial\n",
        "\n",
        "    return final_mse\n"
      ],
      "metadata": {
        "id": "tuS6XgmF5V1B"
      },
      "id": "tuS6XgmF5V1B",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.10"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}